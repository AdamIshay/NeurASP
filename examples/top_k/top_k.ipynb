{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a simple version of the knapsack problem, where each item is associated with a value and the task is to choose a subset of the items that maximizes the sum of the values of the items. We assume there are 10 items with the same weight 2, and the capacity of the knapsack is 15. For example,\n",
    "\n",
    "    [2,7,3,5,2,3,8,2,1,5][1,2,3,4,5,6,9]\n",
    "\n",
    "is a labeled example such that the first list specifies the values of the 10 items and the second list is a solution that specifies the indices of the items to be put into the knapsack. Since the capacity of the knapsack is fixed to be 15 and each item has weight 2, one can infer that the solutions always contain 7 items.\n",
    "## Data Format\n",
    "\n",
    "In dataGen.py, a class named \"KsData\" is defined in the following way.\n",
    "\n",
    "KsData class has 6 attributes: train_data, test_data, valid_data, train_labels, test_labels, valid_labels.\n",
    "\n",
    "train_data is an numpy array of size (1800, 10). It consists of 1800 data as follows \n",
    "\n",
    "        [\n",
    "          data,\n",
    "          ...,\n",
    "          data\n",
    "        ]\n",
    "        \n",
    "where data is a vector (numpy array) of length 10. For example, the data shown below  \n",
    "\n",
    "        [2 2 1 3 1 2 8 1 5 1]\n",
    "        \n",
    "defines the 10 values of the 10 items.  \n",
    "train_labels is an numpy array of size (1800, 10). It consists of 1800 label as follows.  \n",
    "\n",
    "        [\n",
    "          label,\n",
    "          ...,\n",
    "          label\n",
    "        ]\n",
    "\n",
    "where label is a vector (numpy array) of length 10, with k \"1\" and (10-k) \"0\". For example, the label shown below  \n",
    "\n",
    "        [0 0 1 0 0 0 0 0 0 0]\n",
    "\n",
    "means that the item 2 is chosen to be put into the knapsack.  \n",
    "test_data is a numpy array of size (600, 10).   \n",
    "valid_data is a numpy array of size (600, 10).  \n",
    "test_labels is a numpy array of size (600, 10).  \n",
    "valid_labels is a numpy array of size (600, 10).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from dataGen import dataList, obsList, dataListTest, obsListTest\n",
    "from network import FC\n",
    "from neurasp import NeurASP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Rule + Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnRule = '''\n",
    "nn(in(10, k), [true, false]).\n",
    "'''\n",
    "\n",
    "constraint = '''\n",
    "% define maxweight k \n",
    "#const k = 7.\n",
    "% we make a mistake if the total weight of the chosen items exceeds maxweight \n",
    ":- #sum{1, I : in(I,k,true)} > k.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Instantiation\n",
    "- Instantiate neural networks.\n",
    "- Define nnMapping: a dictionary that maps neural network names (i.e., strings) to the neural network objects (i.e., torch.nn.Module object)\n",
    "- Define optimizers: a dictionary that specifies the optimizer for each network (we use the Adam optimizer here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = FC(10, 50, 50, 50, 50, 50, 10)\n",
    "nnMapping = {'in': m}\n",
    "optimizer = {'in': torch.optim.Adam(m.parameters(), lr=0.001)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NeurASP Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeurASPobj = NeurASP(nnRule+constraint, nnMapping, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "Note that our target is to find the set of items with maximal sum of the values, which is represented by the optimal stable models of the logic program. To find the optimal stable models instead of stable models during training, we need to specify \"opt=True\" in the learning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saveModelPath = 'data/model.pt'\n",
    "startTime = time.time()\n",
    "\n",
    "for i in range(20):\n",
    "    print('Epoch {}...'.format(i+1))\n",
    "    time1 = time.time()\n",
    "    NeurASPobj.learn(dataList=dataList, obsList=obsList, epoch=10, opt=True, smPickle='data/stableModels.pickle')\n",
    "    time2 = time.time()\n",
    "    NeurASPobj.testConstraint(dataListTest, obsListTest,[constraint])\n",
    "    print('--- train time: %s seconds ---' % (time2 - time1))\n",
    "    print('--- test time: %s seconds ---' % (time.time() - time2))\n",
    "    print('--- total time from beginning: %s minutes ---' % int((time.time() - startTime)/60) )\n",
    "\n",
    "print('Storing the trained model into {}'.format(saveModelPath))\n",
    "torch.save(m.state_dict(), saveModelPath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
